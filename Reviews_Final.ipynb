{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sentiment Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import enchant\n",
    "import string\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Chargement et visualisation du jeu de données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('reviews.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploration des données"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vérification des valeurs manquantes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Contenu de la colonne Rating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rating_count = df['Rating'].value_counts().sort_values(ascending=True)\n",
    "plt.bar(range(1, 6), rating_count, color='orange')\n",
    "plt.title('Répartition du nombre de commentaires par note');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Contenu de la colonne Review_Text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Review_Length'] = df['Review_Text'].str.split().map(lambda x: len(x))\n",
    "df.sort_values(by='Review_Length', axis=0, ascending=True).head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing de la colonne Review_text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On supprime les 2 reviews qui ont moins de 5 mots : ce sont des messages d'erreur"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df[df['Review_Length'] < 5]['Review_Text'].values)\n",
    "df = df[df['Review_Length'] > 5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On choisit d'appliquer la stemmatisation plutôt que la lemmatisation car on obtient moins de mots et cela pallie au grand nombre de fautes d'orthographe."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PortStem = PorterStemmer()\n",
    "EnglishDict = enchant.Dict(\"en\")\n",
    "\n",
    "def preprocess_reviews(review):\n",
    "    # print('Unprocessed review: \\n', review, '\\n')\n",
    "    review = review.replace('[^\\w\\s]', '')\n",
    "    # print('Removing leading whitespace: \\n', review, '\\n')\n",
    "    review = review.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
    "    # print('Removing punctuation: \\n', review, '\\n')\n",
    "    review = re.sub('[\\d]', '', review)\n",
    "    # print('Removing digits: \\n', review, '\\n')\n",
    "    review = review.lower()\n",
    "    # print('Lowercasing: \\n', review, '\\n')\n",
    "    tokens = word_tokenize(review)\n",
    "    # print('Tokenising: \\n', tokens, '\\n')\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    # print('Removing stopwords: \\n', tokens, '\\n')\n",
    "    tokens = [PortStem.stem(token) for token in tokens if len(token) > 2]\n",
    "    # print('Lemmatising and keeping words more than 2 letters: \\n', tokens, '\\n')\n",
    "    tokens = [token for token in tokens if EnglishDict.check(token)]\n",
    "    # print('Keeping well written words: \\n', tokens, '\\n')\n",
    "    processed_review = ' '.join(tokens)\n",
    "    # print('Processed review: \\n', processed_review, '\\n')\n",
    "    return processed_review"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['processed_review'] = df['Review_Text'].apply(lambda x: preprocess_reviews(x))\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Résultat du processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On peut voir ci-dessous que les phrases ont été correctement nettoyées de ponctuation, des chiffres, des mots de liaisons et articles... et stemmatisées.\n",
    "\n",
    "Cette opération a permis d'économiser 57% du texte (en monbre de mots), ce qui réduit les ressources et le temps pour les traitements, et permet d'interpréter au mieux les textes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Review_Length_preprocessed'] = df['processed_review'].str.split().map(lambda x: len(x))\n",
    "df['diff'] = df['Review_Length_preprocessed'] - df['Review_Length']\n",
    "df['diff'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Exemple review positive (note de {df.loc[20, 'Rating']}) avant / après processing :\\n\")\n",
    "print(df.loc[20, 'Review_Text'], '\\n')\n",
    "print(df.loc[20, 'processed_review'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"Exemple review avant / après processing :\\n\")\n",
    "print(df.loc[17, 'Review_Text'])\n",
    "print(df.loc[17, 'processed_review'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Equilibrage des classes et polarisation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "D'après le diagramme de répartition du nombre de reviews par classe généré au début, on constate que les classes correspondant au Rating est nettement en faveur des commentaires positifs (environ 2/3 - 1/3), ce qui crée un déséquilbre entre les deux classes à mesurer. Ce déséquilibre peut réduire la performance des modèles.\n",
    "\n",
    "Nous avons opté pour faire un rééquilibrage de classes, pour maximiser la performances des modèles."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "L'opération de polarisation permet de diviser le dataset en 2 classes pour la target."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def setClassBin(i):\n",
    "    if i > 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['polar'] = [setClassBin(x) for x in df.Rating]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "polar_count = df['polar'].value_counts().sort_values(ascending=True)\n",
    "print(polar_count)\n",
    "\n",
    "plt.bar(range(0,2), polar_count, color='orange', width = 0.6)\n",
    "plt.xticks([])\n",
    "plt.title('Répartition du nombre de commentaires négatifs (gauche) et positifs (droite)');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On se sert ensuite de la nouvelle colonne pour réduire le nombre de rating positifs au même nombre que les ratings négatifs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_eq = df[df['polar'] == 0]\n",
    "df_eq = df_eq.append(df[df['polar'] == 1][:3955])\n",
    "df_eq.polar.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualisation de l'occurence des mots"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Avec nos données propres, on peut savoir quels sont les mots qui dominent dans le corpus ainsi que dans les ratings positifs et négatifs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Series des mots les plus fréquents"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cette étape permet en premier lieu de connaître la fréquence exacte.\n",
    "On utilise d'abord l'extracteur de features numériques CountVectoriser qui effectue une tokenisation puis un comptage."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CV = CountVectorizer(stop_words = 'english')\n",
    "word_count = CV.fit_transform(df['processed_review'])\n",
    "word_count = pd.DataFrame(word_count.toarray(), columns=CV.get_feature_names())\n",
    "word_count = word_count.apply('sum', axis=0).sort_values(ascending=False)\n",
    "word_count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On remarque que le mot park est très largement présent dans le corpus, ainsi que ride, time, day.\n",
    "Nous extraierons ces mots dans certains wordclouds car ils ne permettent pas de différencier les reviews."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Wordclouds\n",
    "\n",
    "On créé une liste de mots que l'on voudra exclure car ils n'informent pas sur la polarité. On prend les 10 mots les plus présents et d'autres mots qui n'apportent pas beaucoup de sens tel que went, also."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "excluded_words = set(list(word_count.index)[:10])\n",
    "excluded_words.update(['really', 'get', 'went', 'one', 'would', 'also'])\n",
    "excluded_words"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On fusionne le texte qu'on veut visualiser."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in df_eq.processed_review)\n",
    "text_positive = \" \".join(review for review in df_eq[df_eq['polar'] == 1].processed_review)\n",
    "text_negative = \" \".join(review for review in df_eq[df_eq['polar'] == 0].processed_review)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On créé 6 wordclouds :\n",
    "\n",
    "- 1ere ligne : sans exclusion de mots\n",
    "- 2eme ligne : avec exclusion\n",
    "\n",
    "- 1ere colonne : toutes les reviews\n",
    "- 2eme colonne : reviews positives\n",
    "- 3eme colonne : reviews négatives"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rose_mask = np.array(Image.open(\"mask.jpg\"))\n",
    "\n",
    "word_cloud = WordCloud(background_color = 'white', max_words=50, mask=rose_mask).generate(text)\n",
    "word_cloud_positive = WordCloud(background_color = 'white', max_words=50, mask=rose_mask).generate(text_positive)\n",
    "word_cloud_negative = WordCloud(background_color = 'white', max_words=50, mask=rose_mask).generate(text_negative)\n",
    "\n",
    "word_cloud_2 = WordCloud(background_color = 'white', max_words=50, mask=rose_mask, stopwords=excluded_words).generate(text)\n",
    "word_cloud_positive_2 = WordCloud(background_color = 'white', max_words=50, mask=rose_mask, stopwords=excluded_words).generate(text_positive)\n",
    "word_cloud_negative_2 = WordCloud(background_color = 'white', max_words=50, mask=rose_mask, stopwords=excluded_words).generate(text_negative)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(word_cloud)\n",
    "plt.title('Wordcloud corpus entier')\n",
    "\n",
    "plt.subplot(232)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(word_cloud_positive)\n",
    "plt.title('Wordcloud reviews positives')\n",
    "\n",
    "plt.subplot(233)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(word_cloud_negative)\n",
    "plt.title('Wordcloud reviews négatives')\n",
    "\n",
    "plt.subplot(234)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(word_cloud_2)\n",
    "plt.title('Wordcloud corpus entier - excluded words')\n",
    "\n",
    "plt.subplot(235)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(word_cloud_positive_2)\n",
    "plt.title('Wordcloud reviews positives - excluded words')\n",
    "\n",
    "plt.subplot(236)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(word_cloud_negative_2)\n",
    "plt.title('Wordcloud reviews négatives - excluded words')\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sur la première ligne, les mêmes mots reviennent dans les reviews positives et négatives.\n",
    "Sur la deuxième ligne, on peut distinguer plus de mots qui sont du registre positif et négatif."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Séparation du jeu de données avec cross validation\n",
    "On prépare le jeu de données avec 2 types de targets que nous utiliserons en fonction du nombre de classes à prédire\n",
    "- y_5 : colonne originale contenant 5 classes\n",
    "- y_2 : colonne polarisée avec 2 classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "X = df_eq['processed_review']\n",
    "y_5 = df_eq['Rating']\n",
    "y_2 = df_eq['polar']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=21)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Cross validation pour y_5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "for train_index, test_index in folds.split(X, y_5):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_5_train, y_5_test = y_5.iloc[train_index], y_5.iloc[test_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Cross validation pour y_2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for train_index, test_index in folds.split(X, y_2):\n",
    "    y_2_train, y_2_test = y_2.iloc[train_index], y_2.iloc[test_index]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On vérifie les dimensions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Dimensions données d\\'entrainement: ', X_train.shape, y_5_train.shape, y_2_train.shape)\n",
    "print('Dimensions données test :', X_test.shape, y_5_test.shape, y_2_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implémentation des algorithmes\n",
    "\n",
    "On utilisera plusieurs algorithmes ainsi qu'un nombre de classes différent à prédire."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Vectorisation\n",
    "Cette étape est commune à tous nos algorithmes.\n",
    "En effet, les reviews ne peuvent pas être données tel quel: l'algorithme a besoin de vecteurs numériques de longueur fixe plutôt que du texte brut à longueur variable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CV = CountVectorizer(stop_words = 'english')\n",
    "X_train_CV = CV.fit_transform(X_train)\n",
    "X_test_CV = CV.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On obtient ainsi la matrice suivante :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CV_df = pd.DataFrame(X_train_CV.toarray(), columns=CV.get_feature_names())\n",
    "CV_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Régression logistique (2 classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Il est intéressant de comparer la régression logistique au Complement Naive Bayes sur ce corpus de données, avec la fonction  StratifiedKFold pour créer les jeux de test / train, plus performant que le train_test_split, en partant des classes rééquilibrées (dataframe df_eq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On vectorise le jeu de données, et on affiche la matrice de mots et ses dimensions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test_CV.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_df_log = pd.DataFrame(X_test_CV.toarray(), columns=CV.get_feature_names())\n",
    "cv_df_log"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cv_df_log.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Paramétrage du modèle :"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Clist = [0.01, 0.05, 0.25, 0.5, 1, 1.25, 1.5, 2, 2.5, 3, 5]\n",
    "Accs = []\n",
    "\n",
    "for c in Clist:\n",
    "    lr = LogisticRegression(C=c)\n",
    "    lr.fit(X_test_CV, y_2_test)\n",
    "    acc = accuracy_score(y_2_test, lr.predict(X_test_CV))\n",
    "    Accs.append(acc)\n",
    "    print (\"Précision TEST pour C=%s: %s\" % (c, acc))\n",
    "\n",
    "# for c in Clist:\n",
    "#     lr = LogisticRegression(C=c)\n",
    "#     lr.fit(X_train_CV, y_2_train)\n",
    "#     acc = accuracy_score(y_2_train, lr.predict(X_train_CV))\n",
    "#     Accs.append(acc)\n",
    "#     print (\"Précision TRAIN pour C=%s: %s\" % (c, acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(Clist,Accs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "le modèle est le plus optimal avec un hyper-paramètre C=5 (0,945) sur les données de test\n",
    "Sur les données de Train, on est à 0,98"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = cross_val_score(LogisticRegression(), X_test_CV, y_2_test, scoring='accuracy', cv=5)\n",
    "print(\"performances des folds :\", results)\n",
    "print(\"performance globale du modèle :\", np.mean(cross_val_score(LogisticRegression(), X_test_CV, y_2_test, scoring='accuracy', cv=5)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict(X_test_CV)\n",
    "y_pred_train = lr.predict(X_train_CV)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calcul et affichage de la matrice de confusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matrice_confusion = confusion_matrix(y_2_test, y_pred_test)\n",
    "print(\"Matrice de Confusion:\\n\",  matrice_confusion)\n",
    "\n",
    "print(\"\\nLe modèle a fait\", matrice_confusion[0, 1], \"Faux Positifs.\")\n",
    "print(\"\\nLe modèle a fait\", matrice_confusion[1, 0], \"Faux Positifs.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calcul de l'accuracy, precision et rappel"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(VN, FP), (FN, VP) = confusion_matrix(y_2_test, y_pred_test)\n",
    "n = len(y_2_test)\n",
    "\n",
    "print(\"\\nModel Accuracy:\", (VP + VN) / n)\n",
    "\n",
    "print(\"\\nModel Précision:\", VP / (VP + FP))\n",
    "\n",
    "print(\"\\nModel Rappel:\", VP / (VP + FN), \"\\n\")\n",
    "\n",
    "print(\"matrice de confusion TEST :\\n\",pd.crosstab(y_2_test, y_pred_test, rownames=['Realité'], colnames=['Prédiction']), \"\\n\")\n",
    "print(\"Classification report de train = \\n\", classification_report (y_2_train, y_pred_train))\n",
    "print(\"Classification report de test = \\n\", classification_report (y_2_test, y_pred_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Après avoir utilisé KfoldStratifier & Corss_val_score : on remarque que modèle sature les ressources du serveur, et renvoie des warnings qui empêchent l'affichage (donc on empiètent sur les calculs) des résultats, ce qui les rend peu fiables.\n",
    "Mais l'Accuracy globale affichée est de  de 0,8029\n",
    "\n",
    "Train_test_split n'arrive pas à calculer le modèle.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Complement Naive Bayes (2 classes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnb = ComplementNB()\n",
    "cnb.fit(X_train_CV, y_2_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Résultats Complement Naive Bayes données d\\'entraînement :', cnb.score(X_train_CV, y_2_train))\n",
    "print('Résultats Complement Naive Bayes données test :', cnb.score(X_test_CV, y_2_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_result = cnb.predict(X_test_CV)\n",
    "print(classification_report(y_2_test, predicted_result))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Interprétation des résultats*\n",
    "\n",
    "On obtient un score d'environ 83% sur nos données test ce qui est environ 3% de moins que sur les données d'entraînement. Cela valide assez bien notre modèle mais il n'est pas aussi performant que la régression logistique.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Multinomial Naive Bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.1 CountVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_CV, y_5_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Résultats Multinomial Naive Bayes données d\\'entraînement :', clf.score(X_train_CV, y_5_train))\n",
    "print('Résultats Multinomial Naive Bayes données test :', clf.score(X_test_CV, y_5_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_result = clf.predict(X_test_CV)\n",
    "print(classification_report(y_5_test, predicted_result))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Interprétation des résultats*\n",
    "\n",
    "Le modèle est plus précis pour prédire les extrémités : 52% pour les notes de 1 et 69% pour les notes 5.\n",
    "Cela montre les challenges de la classification de texte où les nuances sont difficiles à prendre en compte."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TV = TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "X_train_tfidf = TV.fit_transform(X_train)\n",
    "X_test_tfidf = TV.transform(X_test)\n",
    "\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_test_tfidf.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CV_tfidf = pd.DataFrame(X_train_tfidf.toarray(), columns=TV.get_feature_names())\n",
    "\n",
    "print('Ici les mots sont représentés par des floats car on ajoute un poids à chaque mot en fonction de sa fréquence.')\n",
    "CV_tfidf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf2 = MultinomialNB()\n",
    "\n",
    "clf2.fit(X_train_tfidf, y_5_train)\n",
    "print(clf2.score(X_train_tfidf, y_5_train))\n",
    "\n",
    "print (clf2.score(X_test_tfidf, y_5_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_result_2 = clf2.predict(X_test_tfidf)\n",
    "print(classification_report(y_5_test, predicted_result_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Interprétation des résultats*\n",
    "\n",
    "On observe également une meilleure précision pour les notes extrêmes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. SGDClassifier avec GridSearch\n",
    "Nous tenterons une dernière approche, GridSearch, qui nous permet de trouver les meilleurs paramètres pour un algorithme donné."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "On définit un pipeline contenant les instances des vectorizers, et un algorithme."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", LogisticRegression()),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le dictionnaire de paramètres peut être customisé. Plus de paramètres donnent plus d'exploration mais prennent plus de temps."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    \"clf__max_iter\": (20,),\n",
    "    \"clf__alpha\": (0.00001, 0.000001),\n",
    "    \"clf__penalty\": (\"l2\", \"elasticnet\"),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Enfin la fonction GridSearchCV permet d'effectuer une recherche du meilleur parametrage pour l'algorithme donné dans le pipeline."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "\n",
    "t0 = time()\n",
    "grid_search.fit(X, y_2)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ce projet a permis d'essayer plusieurs algorithmes afin de trouver la meilleure prediction possible. Les scores varient en fonction du nombre de classes à prédire mais aussi de l'algorithme et des paramètres.\n",
    "Une amélioration à ce projet serait d'employer des méthodes state-of-the-art de NLP et de Machine Learning, comme le Deep Learning et Bert."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}